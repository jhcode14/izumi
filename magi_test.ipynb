{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Magi against Manga/Comic in Japanese\n",
    "\n",
    "The Manga Whisperer (Magi), developed by Ragav Sachdeva and Andrew Zisserman aims to automatically generate transcript for comics. It impressively detects panels, text blocks, and characters, and organized each transcripts character by character.\n",
    "\n",
    "- Paper: https://arxiv.org/pdf/2401.10224\n",
    "- Hugging Face: https://huggingface.co/ragavsachdeva/magi\n",
    "\n",
    "The goal of this notebook is to see how suitable is magi at detecting Japanese in comics.\n",
    "\n",
    "I had trouble running the given example code, running magi directly from HF's transformers library on my M3 Mac, thus, I cloned and put the repo within the project and accessed it directly.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhasu/Documents/GitHub/izumi/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports and configerations\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./magi\")  # Add the magi directory to Python path\n",
    "\n",
    "img_location = \"./test_manga\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image_as_np_array(image_path):\n",
    "    with open(image_path, \"rb\") as file:\n",
    "        image = Image.open(file).convert(\"L\").convert(\"RGB\")\n",
    "        image = np.array(image)\n",
    "    return image\n",
    "\n",
    "# Get all img path\n",
    "images = [f\"{img_location}/{x}\" for x in os.listdir(img_location)]\n",
    "images = [read_image_as_np_array(image) for image in images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if MPS (Metal Performance Shaders) is available for Apple Silicon\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jhasu/Documents/GitHub/izumi/.venv/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from magi.configuration_magi import MagiConfig\n",
    "from magi.modelling_magi import MagiModel\n",
    "\n",
    "# Read the config file\n",
    "with open(\"./magi/config.json\", \"r\") as f:\n",
    "    config_dict = json.load(f)\n",
    "\n",
    "# Create the MagiConfig instance\n",
    "config = MagiConfig(**config_dict)\n",
    "\n",
    "# Create the model directly using MagiModel\n",
    "model = MagiModel(config).to(device)\n",
    "\n",
    "# Load the state dict if you have local weights\n",
    "state_dict = torch.load(\"./magi/pytorch_model.bin\", map_location=device)\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    results = model.predict_detections_and_associations(images)\n",
    "    text_bboxes_for_all_images = [x[\"texts\"] for x in results]\n",
    "    ocr_results = model.predict_ocr(images, text_bboxes_for_all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(images)):\n",
    "    model.visualise_single_image_prediction(images[i], results[i], filename=f\"image_{i}.png\")\n",
    "    model.generate_transcript_for_single_image(results[i], ocr_results[i], filename=f\"transcript_{i}.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./test_magi_results/image_1.png\" style=\"width:300px\" />\n",
    "\n",
    "As shown, model impressively detected texts. However, as shown below, the transcript for it attempts to find alphanumeric characters instead of Japanese characters. Thus is not perticularly helpful in this project.\n",
    "\n",
    "```\n",
    " ### Transcript ###\n",
    "<1>: This week is\n",
    "<1>: 30.5.7.4% of the amount\n",
    "<?>: About 10,000%\n",
    "<?>: 1.7.3.7D The\n",
    "<1>: 27(1) The Council:\n",
    "<1>: “I think it’s a good thing,” he said.\n",
    "<4>: “But\n",
    "<?>: SEME!\n",
    "<?>: #1: \"All right here!\"\n",
    "<?>: It is difficult to be\n",
    "<?>: I'm sure that\n",
    "<?>: Too the best\n",
    "\n",
    "```\n",
    "\n",
    "Edit: I later also realized that this model is trained with English comics. Thus is not a great fit for my need."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
